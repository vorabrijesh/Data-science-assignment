{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text preprocessing \n",
    "This assignment is to give hands on experience in text pre processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Write commands to import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this assignment, use the file \"sherlock.txt\" Load the file and print it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for calling text file\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check the length of the file and print first 500 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total characters in sherlock.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First 500 characters in sherlock\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Sentance Tokanization\n",
    "\n",
    "Perform sentence tokanization and show the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sentence Tokenization â€“ Splitting sentences\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Normalize the Text\n",
    "\n",
    "Text includes a lot of punctuation, which we need to remove if we want to work only with the actual words.\n",
    "\n",
    "Write a snippet to remove all the numerals and punctuation from the text and convert the words to lower case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove numeric digits\n",
    "\n",
    "\n",
    "# remove punctuation and make lower case\n",
    "\n",
    "\n",
    "# print the normalized text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Word Tokenization\n",
    "\n",
    "Perform word tokanization and show the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text into individual words\n",
    "\n",
    "\n",
    "# Get the frequency distribution of the words\n",
    "\n",
    "\n",
    "# Display the frequency distribution as a histogram (top 50 words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Remove Stopwords\n",
    "You can see that a large number of the words in the text are common words like \"the\" or \"and\". These are called  \"stopwords\" and  add little in the way of semantic meaning to the text and won't help to determine the subject matter \n",
    "\n",
    "Write a snippet to remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stopwords from the text\n",
    "\n",
    "# Get the frequency distribution of the remaining words\n",
    "\n",
    "# Plot the frequency of the top 50 words\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Extract Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get n-grams where n = 2\n",
    "\n",
    "\n",
    "# Count the frequency of each n-gram\n",
    "\n",
    "# Plot the frequency of the top 25 bigrams\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Stem the words\n",
    "\n",
    "Write a code to stem the words and count the stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the word stems\n",
    "\n",
    "\n",
    "# Get Frequency distribution\n",
    "\n",
    "\n",
    "# Plot the frequency of the top 25 stem words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Lemmatize the Words\n",
    "\n",
    "Write a code to lemmatize the words and count the lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the word lemmas\n",
    "\n",
    "\n",
    "# Get Frequency distribution\n",
    "\n",
    "\n",
    "# Plot the frequency of the top 25 lemma words"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
